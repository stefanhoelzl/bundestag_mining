name: download, parse, analyze and publish pipeline

on:
  push:
  # schedule:
  #   - cron:  '0 5 * * *'

jobs:
  download:
    runs-on: ubuntu-latest
    steps:
      - name: checkout
        uses: actions/checkout@v1
        with:
          fetch-depth: 1
      - name: setup python
        uses: actions/setup-python@v1
        with:
          python-version: '3.8'
      - name: install requirements
        shell: bash
        run: pip install -r requirements.txt
      - name: crawl data
        shell: bash
        run: python src/crawler.py
      - name: parse data
        shell: bash
        run: python src/parser.py
      - name: generate html
        shell: bash
        run: python src/generator.py
      - name: deploy html
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GH_TOKEN }}
          publish_dir: ./html
          allow_empty_commit: true
      - name: package data for upload
        shell: bash
        run: mkdir upload && tar -czvf upload/data.tar.gz data && tar -czvf upload/html.tar.gz html && tar -czvf upload/rst.tar.gz rst
        if: always()
      - name: upload data
        uses: actions/upload-artifact@v1
        if: always()
        with:
          name: upload
          path: upload
